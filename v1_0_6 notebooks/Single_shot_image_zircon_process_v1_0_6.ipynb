{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Single_shot_image_zircon_process_v1-0-6.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yL0b7kBpW1Le",
        "Vj4IX9Rll27E"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0dY5QyIbASi"
      },
      "source": [
        "# Automatic and Semi-Automatic Zircon Measurement Notebook for Non-ALC Datasets\n",
        "The code in this Colab Notebook will automatically detect, segment, and measure zircon crystals in reflected light alignment single-shot images centered on LA-ICP-MS dated crystals. Zircon segmentation is accomplished via trained Mask RCNN model, using the Detectron2 deep learning library. Images for segmentation will ideally have been saved with scaling metadata files during LA-ICP-MS dating (e.g., at the UCSB LASS facility), but scaling information for images can be added manually for non-standardized images.\n",
        "\n",
        "This Notebook is ready-to-run and implements code available in the [colab-zirc-dims GitHub repository](https://github.com/MCSitar/colab_zirc_dims). Before using this Notebook, it should be copied into your own Google Drive (location w/in is irrelevant) or opened in 'playground mode'. Make sure that you are connected to a GPU runtime when running this Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to run this Notebook (for new Google Colab users):"
      ],
      "metadata": {
        "id": "yL0b7kBpW1Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab notebooks are Jupyter notebooks that execute in cloud-hosted Python 3 environments on virtual machines equiped with high-end CPUs and GPUs. Users are thus able to run compute-intensive Python code, view outputs, etc. in a browser window from any local computer regardless of their hardware and without any setup or installation.\n",
        "\n"
      ],
      "metadata": {
        "id": "AKJMCMF4XKtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking GPU runtime:"
      ],
      "metadata": {
        "id": "MdNJ-uIYbSi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code in this Notebook uses RCNN models to segment zircon crystals from images, so virtual runtimes executing it require access to a GPU. This should be enabled by default, but if users want to verify that their virutal machine has a GPU:\n",
        "\n",
        "1.   Navigate to 'Runtime' --> 'Change runtime type' in the toolbar at the top of the screen.\n",
        "2.   In the 'Notebook Settings' window that pops up, check that 'GPU' is selected in the 'Hardware accelerator' dropdown menu. If not, select it.\n",
        "3.   Click save, then run the Notebook.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I7jCAFt5baTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running cells:"
      ],
      "metadata": {
        "id": "PO9ZCoHDeMKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebooks are made up of cells containing either text or code. Cells with code in this Notebook should be run in top-bottom order unless otherwise specified. To run cells:\n",
        "\n",
        "1.   Hover the mouse over the cell to be run, then click the button with a 'play' symbol on it. See below for an example:"
      ],
      "metadata": {
        "id": "dGkFQ6mNeMKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Try running this example cell\n",
        "print('Cell run!')"
      ],
      "metadata": {
        "id": "y0LoYb_Mf4CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clearing outputs:"
      ],
      "metadata": {
        "id": "CtUo23yWgInW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make this Notebook look neater after running it and/or to cut down on file size before saving (e.g., if there are many inspection images open), users can clear all cell outputs. To do this:\n",
        "\n",
        "1.   Navigate to 'Edit' --> 'Clear all outputs' in the toolbar at the top of the screen, then click."
      ],
      "metadata": {
        "id": "bQ0mP2FJgpQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Factory reset runtime:"
      ],
      "metadata": {
        "id": "z_Qzu57xhvrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some earlier versions of this project had memory leak issues that caused RAM crashes during fully-automated grain processing. Said issues seem to be fixed, but if they reappear:\n",
        "\n",
        "1.   Clear the current virtual machine runtime and connect to a new one (with fresh RAM) by navigating to 'Runtime' --> 'Factory reset runtime' and clicking.\n",
        "2.   Re-run all neccesary cells in Notebook.\n",
        "3.   (Please) open an issue on the project Github page or use the contact details found there to report the bug directly to the project manager.\n"
      ],
      "metadata": {
        "id": "9nCcoQ_xh2xO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Possible Workflows:"
      ],
      "metadata": {
        "id": "jBkTjTKx17qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Only using automated processing (not recommended)\n",
        "1. Run cells in 'Processing Option A' after running all required cells above. This is the only step.\n",
        "\n",
        "#### Sample-by-sample semi-automated processing \n",
        "1.   Run the GUI in 'Processing Option B' after running all required cells above.\n",
        "2.   Produce and correct segmentations and measurements on a sample-by-sample basis\n",
        "\n",
        "#### Automated editing followed by manual segmentation checking/editing\n",
        "1. Run cells in 'Processing Option A' with polygon saving enabled after running all required cells above.\n",
        "2.   Load polygons and use the GUI ('Processing Option B') to check and/or edit auto-generated polygons. Can be done in a single sesssion or iteratively in multiple sessions; load polygons from your last semi-automated processing run to pick up where you left off."
      ],
      "metadata": {
        "id": "D-woZ0kv2FqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Data Formatting and Organization:"
      ],
      "metadata": {
        "id": "h6-ooPG62Umh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this Notebook, a formatted project folder containing your data files must be uploaded to your Google Drive. A 'sample_info.csv' file with scaling information may be included in the folder if needed.\n",
        "\n",
        "Your project folder must be organized following a structure shown below (in 'Project Folder Organization Options'), depending on use-case. \n"
      ],
      "metadata": {
        "id": "q3xUNZWF2b2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Folder Organization Options:"
      ],
      "metadata": {
        "id": "frPyk-vjivba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option A: Sample information included in file names"
      ],
      "metadata": {
        "id": "ztcOBVyrhY7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this format if image (+/- .Align file) filenames contain sample names (e.g., saved images from UCSB have format 'ScanImage_ **SAMPLE_NAME** - **SHOT_NUMBER** ... .png'). In this case, sample names will be extracted and used to organize your dataset automatically during data loading. If your dataset does not have sample names, you can also use this option by simply adding all files to the 'scans' directory.\n",
        "\n",
        "A template project folder with this format that can be downloaded, edited, and re-uploaded is available [here](https://drive.google.com/drive/folders/1MkWh9PRArbV1m1eVbSTbb9C5PKC95Re3?usp=sharing).\n",
        "\n",
        "```\n",
        "root directory\n",
        "|   sample_info.csv*\n",
        "|\n",
        "└───scans\n",
        "│   │   XXX_SAMPLE-SCAN.png\n",
        "│   │   XXX_SAMPLE-SCAN.Align**\n",
        "│   │   YYY_SAMPLE-SCAN.png\n",
        "│   │   YYY_SAMPLE-SCAN.Align**\n",
        "|   |   ...\n",
        "|\n",
        "└───outputs***\n",
        "    |   ...\n",
        "\n",
        "*Optional; can be used to provide scaling info for datasets without .Align \n",
        " scaling metadata files. If neither are present, a scale of 1.0 μm/pixel will\n",
        " be assumed.\n",
        "\n",
        "**Optional; if present must have same names (except for file suffix) as\n",
        "  corresponding image files.\n",
        "\n",
        "***Optional; if this folder does not exist it will be automatically created\n",
        "   during processing\n",
        "```"
      ],
      "metadata": {
        "id": "S4EGnkpihyDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option B: Dataset scan images organized into folders by sample"
      ],
      "metadata": {
        "id": "KnGfmduXh37A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this format if image (+/- .Align file) filenames do not contain sample names (e.g., images might have format '**SHOT_NUMBER** ... .png'). In this case, names of sub-folders containing scans will be used as sample names and used to organize your dataset automatically during data loading.\n",
        "\n",
        "A template project folder with this format that can be downloaded, edited, and re-uploaded is available [here](https://drive.google.com/drive/folders/1VpYo5HwDUaAQ4lJ0waZJRDrWkzHv2QyM?usp=sharing).\n",
        "\n",
        "\n",
        "```\n",
        "root directory\n",
        "|   sample_info.csv*\n",
        "|\n",
        "└───scans\n",
        "│   │\n",
        "│   └───SAMPLE_XXX\n",
        "│   │   │   SCAN-1.png\n",
        "│   │   │   SCAN-1.Align**\n",
        "│   │   │   SCAN-2.png\n",
        "│   │   │   SCAN-2.Align**\n",
        "|   |   │   ...\n",
        "│   │\n",
        "|   |───SAMPLE_YYY\n",
        "│   │   │   SCAN-1.png\n",
        "│   │   │   SCAN-1.Align**\n",
        "│   │   │   SCAN-2.png\n",
        "│   │   │   SCAN-2.Align**\n",
        "|   |   │   ...\n",
        "|   |   ...\n",
        "|\n",
        "|\n",
        "└───outputs***\n",
        "    |   ...\n",
        "\n",
        "*Optional; can be used to provide scaling info for datasets without .Align \n",
        " scaling metadata files. If neither are present, a scale of 1.0 μm/pixel will\n",
        " be assumed.\n",
        "\n",
        "**Optional; if present must have same names (except for file suffix) as\n",
        "  corresponding image files.\n",
        "\n",
        "***Optional; if this folder does not exist it will be automatically created\n",
        "   during processing\n",
        "```"
      ],
      "metadata": {
        "id": "vWLCMVRvi69Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sample_info.csv Formatting"
      ],
      "metadata": {
        "id": "98IjtM9t2oz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you include a sample_info csv file in your project folder, it must have headers (capitalization must match):\n",
        "\n",
        "| **Sample** | **Scale** |\n",
        "\n",
        "Data that should be entered under each of the headers will be as follows:\n",
        "\n",
        "\n",
        "*   **Sample**: Name of each sample, matchable either to scan names or to data subfolders, depending on directory organization (e.g., 'V26').\n",
        "*   **Scale**: Scale for images from a sample in μm/pixel.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "i-M2XN8D2utt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06yBm0pRreAd"
      },
      "source": [
        "## Setup and Installation:\n",
        "\n",
        "\n",
        "The 2 cells below (modified from the [Detectron2 Colab tutorial](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)) will install Detectron2 and import various packages neccesary for further processing. The runtime will automatically restart upon Detectron2 installation in the first cell (may bring up crash warning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puL6ZbwlppA7"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s3s-2F8JmjI"
      },
      "source": [
        "# import some neccesary libraries\n",
        "import os, cv2, sys\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import ipywidgets as widgets\n",
        "%matplotlib auto\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import catalog\n",
        "\n",
        "#install colab_zirc_dims\n",
        "!pip install colab_zirc_dims==1.0.6\n",
        "\n",
        "#import colab_zirc_dims modules\n",
        "from colab_zirc_dims import save_load\n",
        "from colab_zirc_dims import alc_notebook_fxns\n",
        "from colab_zirc_dims import zirc_dims_GUI\n",
        "from colab_zirc_dims import gen_notebook_fxns\n",
        "from colab_zirc_dims import gen_filename_fxns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkqTw8-cjB3E"
      },
      "source": [
        "\n",
        "To mount your Google Drive, simply run the cell below and input your authentication code as requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcNfpP3BsJVE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhjGHLedsOhT"
      },
      "source": [
        "Modify the form field and run the cell below to set your project directory (organized as above) as the root directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYRKBqn9sNvZ"
      },
      "source": [
        "#@title Input full path to project folder here, then run this cell\n",
        "ROOT_DIR = \"/content/drive/My Drive/YOUR PROJECT DIRECTORY HERE\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6wy-6GJWXpY"
      },
      "source": [
        "## Data Loading:\n",
        "\n",
        "The cells below will allow you to select loading options and load your dataset into the notebook. The 'splitting fxn' parameter defines a function that is used to extract scan +/- sample names from image filenames, and a custom function can optionally be implemented here. See 'Data Formatting and Organization' above for more info on possible project directory structure and how to format a sample_info.csv scale file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define a custom function for extracting sample, scan info from file names (optional):"
      ],
      "metadata": {
        "id": "Vj4IX9Rll27E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your image filenames contain sample/scan info in a format that is not currently supported by this notebook (i.e., [not defined here](https://github.com/MCSitar/colab_zirc_dims/blob/main/colab_zirc_dims/gen_filename_fxns.py)), you can define a custom function for extracting this information from file names here and then run the cell. If you do write a custom function that works for datasets with a currently-unsupported file name format, please consider submitting a pull request or contacting the colab_zirc_dims project manager so that other users can use this function."
      ],
      "metadata": {
        "id": "XEeCz4Bhl_S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#edit the function below\n",
        "def custom_name_split(filename):\n",
        "  ## Some code to extract a sample name string (can be a placeholder if\n",
        "  ## this info is not actually in file names) and scan name string from\n",
        "  ## the filename of each image in your dataset.\n",
        "  return 'PLACEHOLDER_SAMPLE_NAME', filename.strip('.png')\n",
        "\n",
        "name_splitting_fxs = {'UCSB': gen_filename_fxns.split_name_ucsb,\n",
        "                      'Custom function': custom_name_split,\n",
        "                      'Use full image file name': None}"
      ],
      "metadata": {
        "id": "qWaV4fTl0A4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset:\n",
        "Run the cell below to select options and load your dataset. Re-run this cell and the one below ('Select Samples') if you have made any changes to structure/files  (e.g., sample_info.csv) in your project directory since last running it."
      ],
      "metadata": {
        "id": "MilQv-fWmMkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_args_list = []\n",
        "loaded_data_dict = {}\n",
        "try:\n",
        "    gen_notebook_fxns.gen_data_load_interface(ROOT_DIR, load_args_list,\n",
        "                                              loaded_data_dict,\n",
        "                                              name_splitting_fxs)\n",
        "except NameError:\n",
        "    gen_notebook_fxns.gen_data_load_interface(ROOT_DIR, load_args_list,\n",
        "                                              loaded_data_dict,\n",
        "                                              gen_filename_fxns.default_name_fxns)"
      ],
      "metadata": {
        "id": "apA6piCrv5wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Selection:\n",
        "Run the cell below to select loaded samples for processing using dynamically-created checkboxes."
      ],
      "metadata": {
        "id": "964qwhY_s0EJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUDPgQLFWXpZ"
      },
      "source": [
        "#Selection of samples from dataset for processing\n",
        "selected_samples = []\n",
        "if len(list(loaded_data_dict.keys())):\n",
        "  alc_notebook_fxns.select_samples_fxn(loaded_data_dict, selected_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O682T15T0AxA"
      },
      "source": [
        "## Data Inspection (optional):\n",
        "Run the cell below to inspect (display random samples of images from each sample) selected data from each dataset in your project directory. Scales for\n",
        "images are in microns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "gen_notebook_fxns.gen_inspect_data(loaded_data_dict,\n",
        "                                   selected_samples,\n",
        "                                   n_scans_sample = 3) #modify integer here to change\n",
        "                                                       # number of scans sampled from\n",
        "                                                       # each sample.\n",
        "%matplotlib auto"
      ],
      "metadata": {
        "id": "mw20ZRc0pa0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTxOTyV2WXpd"
      },
      "source": [
        "## Model Download and Initialization:\n",
        "\n",
        "The cells below will download (1st cell) and then initialize and configure (2nd cell) a trained zircon-segmentation RCNN model. This model will be used to segment zircon crystals from the images that you previously loaded.\n",
        "\n",
        "Model training parameters and comparisons between model results and segmentations/measurements by humans will (hopefully) be made available in a future publication. It is recommended that users pick one of the first two models, and that they avoid the last 3 models (these do not perform well and are only included for manuscript data replication purposes)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify path/url below if you want to use a custom (with downloadable models)\n",
        "# model library with this Notebook. Models are currently hosted for download on AWS;\n",
        "# see czd_model_library.json for direct download links and model lib formatting.\n",
        "\n",
        "model_lib_loc = 'default' #this will get the current version of the czd model lib from Github\n",
        "\n",
        "current_model_dict = {}\n",
        "alc_notebook_fxns.select_download_model_interface(current_model_dict, model_lib_loc)"
      ],
      "metadata": {
        "id": "KEQM4ijgTQzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZzacbwXWXpd"
      },
      "source": [
        "# Run this cell after selecting a model in the cell above, and again if model is changed at any point.\n",
        "# Can be modified to load any Detectron 2 instance segmentation model trained to \\\n",
        "# detect zircon grains.\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(current_model_dict['config_file']))#base model configuration\n",
        "cfg.MODEL.RESNETS.DEPTH = current_model_dict['resnet_depth'] #set resnet depth from model library\n",
        "cfg.MODEL.WEIGHTS = os.path.join(os.getcwd(), current_model_dict['name']) #loads model weights (trained to detect zircons)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only class here is zircon\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom threshold\n",
        "cfg.MODEL.RPN.NMS_THRESH = 0.06 #set a custom (lower) NMS threshold; ideally minimizes overlapping zircon masks in results\n",
        "\n",
        "zircon_metadata = catalog.Metadata(name='zircon_meta', thing_classes=['zircon'])\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdiJZUitWXpe"
      },
      "source": [
        "## Test Evaluation (Optional):\n",
        "\n",
        "Run the cell below to visualize model prediction results on a random sample of scans from samples. Axes for scanned zircon images will be in microns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "gen_notebook_fxns.gen_test_eval(selected_samples, loaded_data_dict, predictor, \n",
        "                                zircon_metadata,\n",
        "                                n_scans_sample =3) #modify integer to change num. scans\n",
        "                                                  # randomly selected, evaluated per sample.\n",
        "%matplotlib auto"
      ],
      "metadata": {
        "id": "hw_CWl4jrcd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVg-lhyQxgkZ"
      },
      "source": [
        "## Processing Option A: Fully Automated Processing:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to automatically process all selected samples.\n",
        "\n",
        "In the upper part of the cell, you will select alternate image pre-processing/segmentation methods to automatically try in case an initial attempt at segmentation fails. You do not have to select all or any of these alternate methods. Otsu thresholding segmentation (non-RCNN) is particularly sensitive to image artefacts and can produce wildly incorrect results.\n",
        "\n",
        "In the lower part of the cell, you will choose whether to save segmentation polygons (approximating autogenerated masks to within one micron) into .json files. These polygons can be loaded into GUI (see 'Option B' below) for evaluation and/or editing in this or any future Colab session. Saving polygons is recommended for verification purposes and enabled by default, but will slow down automated processing somewhat.\n",
        "\n",
        "After selecting alternate methods and choosing whether to save autogenrated polygons, run the cell to automatically process all selected samples. Zircon dimensions will be saved to .csv files corresponding to each sample, and mask images will be saved as .png files for verification. If polygon saving is enabled, polygons will be saved into .json files for future editing or further verification."
      ],
      "metadata": {
        "id": "NWu2dDIo3J44"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CXrUeitxgkZ"
      },
      "source": [
        "#@title Select processing options, then run this cell to start fully automated proccessing\n",
        "#@markdown #####Alternate segmentation methods:\n",
        "Try_contrast_enhanced_subimage = True #@param {type:\"boolean\"}\n",
        "Try_Otsu_thresholding  = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #####Save polygons for GUI viewing/editing?\n",
        "Save_polygons = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "save_polys_bool = Save_polygons\n",
        "alt_methods = [Try_contrast_enhanced_subimage,\n",
        "               Try_Otsu_thresholding]\n",
        "\n",
        "#@markdown ###### Identifying string for output directory name (can be blank):\n",
        "full_auto_str = '' #@param {type:\"string\"}\n",
        "\n",
        "#Below: actually run fully-automated segmentation for selected samples. \\\n",
        "#If somehow not set in cells above, mpl auto needed here to prevent RAM crash\n",
        "%matplotlib auto\n",
        "run_dir = gen_notebook_fxns.full_auto_proc(ROOT_DIR, selected_samples, loaded_data_dict,\n",
        "                                           predictor, save_polys_bool, alt_methods,\n",
        "                                           full_auto_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtuDo2R4ms4K"
      },
      "source": [
        "## Processing Option B: GUI (Semi-Automated) Processing:\n",
        "\n",
        "The cells below set up and open a simple GUI that allows sample-by-sample creation, inspection, replacement, and export of automatic zircon segmentations. This may be most useful for images/samples that the automatic segmentation model struggles with (e.g., with poor image quality/misalignment or partially exposed zircons).\n",
        "_______________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load saved polygons (optional):"
      ],
      "metadata": {
        "id": "QatmrCJO3UCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is optional; the GUI can be run without any loadable polygons and will in this case simply produce automated segmentations for each sample as the user navigates through their dataset.\n",
        "\n",
        "(Optionally) running one of the two cells below allows loading polygons and limited metadata from a run directory created during a previous automated or semi-automated processing run. Polygons from the selected run directory will be copied to a current run directory, so segmentations can be edited iteratively in different sessions (see 'Workflows' above). Zircon shapes will not be analyzed and new polygons will not be saved until the 'Analyze...' button is clicked in the GUI.\n",
        "\n",
        "*   Run the first cell below if you have just (within this notebook session) completed an automated processing run for your sample with polygon saving enabled and want to check/edit saved zircon segmentations.\n",
        "*   OR\n",
        "*   Type in the folder name of a semi-automated or saving-enabled automated processing run subdirectory (e.g., *../YOUR_PROJECT FOLDER/outputs/NAME_OF_RUN_DIRECTORY*) from this or a previous session to load polygons from it."
      ],
      "metadata": {
        "id": "_sm_94wM3WcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to attempt loading from a just-run automated processing run.\n",
        "try:\n",
        "  loading_dir = save_load.check_loadable(run_dir, verbose=True)\n",
        "except NameError:\n",
        "  print('No run_dir variable found for current session; try finding and manually',\n",
        "        ' adding a loadable run directory in the cell below or proceed without loading.')\n",
        "  loading_dir = None"
      ],
      "metadata": {
        "id": "2bQDWaCk-t-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "tIdd4J2spzjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the name of a loadable run directory from this or a previous session, \\\n",
        "# then run this cell to attempt loading.\n",
        "input_loadable_run_dir = \"OUTPUT RUN FOR LOADING HERE\" #@param {type:\"string\"}\n",
        "loading_dir = save_load.check_loadable(os.path.join(ROOT_DIR, 'outputs',\n",
        "                                                    input_loadable_run_dir),\n",
        "                                       verbose=True)"
      ],
      "metadata": {
        "id": "nirosSG4qa9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open and Run GUI\n"
      ],
      "metadata": {
        "id": "mH0iiaYc-sj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the cell below will actually open the GUI. If a valid previous run was selected, polygons will be loaded from that run. Otherwise, new automated segmentations will be produced on a sample-by-sample basis. Upon invoking the 'Analyze...' functions, zircon dimensions will be saved to .csv files corresponding to each sample, mask images will be saved as .png files for verification, and any changes to polygons will be saved to .json files corresponding to each sample.\n",
        "\n",
        "Because Google Colab will automatically close inactive runtimes, it is recommended that users not leave GUI running but inactive without first saving changes.\n",
        "\n",
        "\n",
        ">**Instructions and tips:**\n",
        ">\n",
        "> Click on the canvas to start a new zircon polygon, and double click to finish the polygon.\n",
        ">\n",
        ">The 'restore orig. polygon' button will revert to the last saved automatically-generated (or, in the case of loaded polygons, possibly human-generated) zircon segmentation if one exists.\n",
        ">\n",
        ">The 'tag scan' button adds a tag to the scan that will persist into the exported image filename and zircon dimensions .csv file. What this tag means is up to the user (e.g., well-exposed zircons could be tagged).\n",
        ">\n",
        ">The 'Save changes to sample polygons' button will send all current polygons in the currently-open sample for .json saving. This will also be done automatically upon switching between samples and sending polygons for grain dimension analysis.\n",
        ">\n",
        ">The 'Analyze sample dimensions and export to Drive' button will send all current polygons in the currently-open sample for .json saving and dimensional analysis and save the results to your Google Drive project folder.\n",
        ">\n",
        ">The 'Analyze... all selected samples' button will measure dimensions of zircon crystals for all samples in the dataset where saved polygons (either generated in current session or loaded from a previous one) are available. For as-of-yet unclear reasons this is a slow process, so it may be best to check/edit all polygons in a dataset before starting it."
      ],
      "metadata": {
        "id": "AtUOqWxW3fqM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXyzx0humsdS"
      },
      "source": [
        "#run this cell to open GUI\n",
        "%matplotlib auto\n",
        "try:\n",
        "  loading_dir = loading_dir\n",
        "except NameError:\n",
        "  loading_dir = None\n",
        "#@markdown ###### Identifying string for new output directory name (can be blank):\n",
        "semiauto_str = '' #@param {type:\"string\"}\n",
        "zirc_dims_GUI.run_gen_GUI(loaded_data_dict, selected_samples, ROOT_DIR, predictor,\n",
        "                          loading_dir, semiauto_str)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}